# ğŸ  Predictor de Precios Inmobiliarios - RegiÃ³n ValparaÃ­so

![Python](https://img.shields.io/badge/Python-3.9+-blue.svg)
![ML](https://img.shields.io/badge/ML-Gradient%20Boosting-green.svg)
![Status](https://img.shields.io/badge/Status-Completo-success.svg)

> Sistema end-to-end de Machine Learning que predice precios de propiedades inmobiliarias utilizando Gradient Boosting, alcanzando RÂ² = 0.67 en datos reales de la RegiÃ³n de ValparaÃ­so.

## ğŸ“Š Resultados Clave

- âœ… **961 propiedades** analizadas (RegiÃ³n de ValparaÃ­so)
- âœ… **RÂ² = 0.67** en conjunto de prueba
- âœ… **MAE = 2,696 UF** (error promedio absoluto)
- âœ… **6 algoritmos** comparados (Linear Regression, Ridge, Lasso, Random Forest, XGBoost, Gradient Boosting)
- âœ… **OptimizaciÃ³n de hiperparÃ¡metros** con RandomizedSearchCV (40 combinaciones)

## ğŸ¯ Problema & SoluciÃ³n

**Problema:**  
El mercado inmobiliario de la RegiÃ³n de ValparaÃ­so carece de herramientas de valoraciÃ³n objetiva, dificultando a compradores e inversionistas identificar oportunidades.

**SoluciÃ³n:**  
Sistema automatizado que:
1. Recolecta datos de propiedades mediante web scraping
2. Realiza anÃ¡lisis exploratorio exhaustivo (EDA)
3. Limpia y procesa datos con transformaciones especÃ­ficas del dominio
4. Entrena y compara mÃºltiples modelos de Machine Learning
5. Predice valores de mercado con precisiÃ³n del 67%

## ğŸ› ï¸ Stack TÃ©cnico

**Data Collection:**
- Python 3.9+
- BeautifulSoup4
- Requests
- Selenium

**Data Processing & Analysis:**
- Pandas
- NumPy
- Scikit-learn

**Machine Learning:**
- Gradient Boosting Regressor (modelo final)
- Random Forest, XGBoost
- Linear Regression, Ridge, Lasso
- RandomizedSearchCV para optimizaciÃ³n
- Cross-validation (5-fold)

**Visualization:**
- Matplotlib
- Seaborn

**Tools:**
- Jupyter Notebook
- Git
- Joblib

## ğŸ“ Estructura del Proyecto

```
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_Scraping_icasas.ipynb        # Web scraping de icasas.cl
â”‚   â”œâ”€â”€ 02_EDA_pre_limpieza.ipynb       # AnÃ¡lisis exploratorio (51 celdas)
â”‚   â”œâ”€â”€ 03_Limpieza.ipynb               # Limpieza y transformaciÃ³n de datos
â”‚   â””â”€â”€ 04_ML.ipynb                     # Modelado, evaluaciÃ³n y optimizaciÃ³n
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                            # Datos scrapeados (995 propiedades)
â”‚   â””â”€â”€ processed/                      # Datos limpios (961 propiedades)
â”œâ”€â”€ models/
â”‚   â””â”€â”€ modelo_final_valparaiso.pkl     # Gradient Boosting optimizado
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## ğŸš€ InstalaciÃ³n y Uso

```bash
# Clonar repositorio
git clone https://github.com/[tu-usuario]/predictor-precios-valparaiso
cd predictor-precios-valparaiso

# Crear ambiente virtual (recomendado)
python -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate

# Instalar dependencias
pip install -r requirements.txt

# Ejecutar notebooks en orden
jupyter notebook
```

## ğŸ“ˆ MetodologÃ­a

### 1. RecolecciÃ³n de Datos (Web Scraping)
- Fuente: [icasas.cl](https://www.icasas.cl)
- Respeto a robots.txt
- 995 propiedades iniciales
- Variables: ubicaciÃ³n, precio, Ã¡rea, caracterÃ­sticas, amenities

### 2. AnÃ¡lisis Exploratorio (EDA)
- **51 celdas** de anÃ¡lisis detallado
- IdentificaciÃ³n de patrones por comuna
- AnÃ¡lisis de distribuciones de precios
- DetecciÃ³n de valores atÃ­picos
- Correlaciones entre variables

### 3. Limpieza y Preprocesamiento
- **CorrecciÃ³n de separadores decimales:** ConversiÃ³n de formato europeo a estÃ¡ndar
- **NormalizaciÃ³n de Ã¡reas:** ConsolidaciÃ³n de `Area m2`, `Ãrea Ãºtil`, `m2 terreno` en:
  - `Area Construida` (mÃ¡ximo entre las tres)
  - `Area Terreno` (mÃ­nimo entre las tres)
- **Manejo de AÃ±o de ConstrucciÃ³n:** CorrecciÃ³n de valores incoherentes (10-20.3 â†’ 2010-2020.3)
- **Flags categÃ³ricos:** CreaciÃ³n de variables `Casa` y `Terreno` basadas en lÃ³gica de negocio
- **EliminaciÃ³n de duplicados:** ReducciÃ³n de 995 â†’ 961 propiedades Ãºnicas
- **Limpieza de amenities:** ConversiÃ³n de columnas binarias (True/False)

### 4. Feature Engineering
- Variables derivadas: edad del inmueble, ratios, densidad
- Encoding de variables categÃ³ricas (OneHotEncoder)
- Manejo de valores faltantes (imputaciÃ³n con medianas)
- Split estratificado por rangos de precio para balancear distribuciones

### 5. Modelado y EvaluaciÃ³n

**Modelos probados:**

| Modelo | CV RÂ² (5-fold) | Test RÂ² | Test MAE (UF) |
|--------|----------------|---------|---------------|
| Linear Regression | 0.46 | 0.51 | 3417 |
| Ridge | 0.46 | 0.52 | 3404 |
| Lasso | 0.46 | 0.51 | 3418 |
| Random Forest | 0.58 | 0.64 | 2786 |
| XGBoost | 0.52 | 0.61 | 2856 |
| **Gradient Boosting** | **0.62** | **0.66** | **2696** |

**Modelo Final: Gradient Boosting Optimizado**
- HiperparÃ¡metros optimizados con RandomizedSearchCV
- 40 combinaciones evaluadas
- ConfiguraciÃ³n Ã³ptima:
  - `n_estimators`: 700
  - `max_depth`: 4
  - `learning_rate`: 0.03
  - `subsample`: 0.8
  - `max_features`: 'sqrt'
  - `min_samples_split`: 5

**ValidaciÃ³n:**
- Cross-validation 5-fold: RÂ² = 0.62
- Split estratificado train/test (80/20)
- Test RÂ² = 0.67 (modelo generaliza correctamente)

## ğŸ“Š InterpretaciÃ³n de Resultados

**RÂ² = 0.67** significa que el modelo explica el **67% de la variabilidad** en los precios de propiedades.

**MAE = 2,696 UF** representa un error promedio de aproximadamente **$102 millones CLP** (considerando UF â‰ˆ $38,000).

**Contexto:**
- El 33% de variabilidad no explicada corresponde a factores no capturados en el dataset (ubicaciÃ³n exacta, estado de conservaciÃ³n, vista, proximidad a servicios).
- Para un proyecto basado en web scraping sin datos premium (GPS, fotos, tasaciones profesionales), estos resultados son sÃ³lidos.

## ğŸ“ Aprendizajes Clave

1. **Importancia del preprocesamiento:** La correcciÃ³n de separadores decimales y normalizaciÃ³n de Ã¡reas fue crÃ­tica para la calidad del modelo.

2. **Split estratificado:** Implementar estratificaciÃ³n por rangos de precio eliminÃ³ el sesgo de distribuciÃ³n entre train/test.

3. **Gradient Boosting vs Random Forest:** GB superÃ³ a RF en este dataset, probablemente por la capacidad de GB de corregir errores iterativamente.

4. **Hyperparameter tuning:** La optimizaciÃ³n mejorÃ³ el RÂ² de 0.46 (baseline) a 0.67 (optimizado), un incremento del 46%.

5. **Feature engineering especÃ­fico del dominio:** Variables como `Casa`/`Terreno` basadas en lÃ³gica inmobiliaria mejoraron el modelo.

## ğŸ”® PrÃ³ximos Pasos

- [ ] Ampliar a otras regiones (Santiago, ConcepciÃ³n)
- [ ] Implementar sistema de detecciÃ³n de oportunidades (propiedades infravaloradas)
- [ ] Dashboard interactivo con Streamlit
- [ ] AutomatizaciÃ³n de scraping y reentrenamiento

## ğŸ“« Contacto

**[SebastiÃ¡n NÃºÃ±ez]**
- ğŸ“§ Email: [snunez445@gmail.com]
- ğŸ’¼ LinkedIn: [www.linkedin.com/in/sebastiÃ¡n-mauricio-nÃºÃ±ez-pÃ©rez-de-arce-98612534a]
---
